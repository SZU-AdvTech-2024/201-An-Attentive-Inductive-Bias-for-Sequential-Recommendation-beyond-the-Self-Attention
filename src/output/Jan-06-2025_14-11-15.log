2025-01-06 14:11:16,962 - Namespace(data_dir='./data/', output_dir='output/', data_name='Beauty', do_eval=True, load_model='BSARec_Beauty_best', train_name='Jan-06-2025_14-11-15', num_items=10, num_users=22364, lr=0.001, batch_size=256, epochs=200, no_cuda=False, log_freq=1, patience=10, num_workers=4, seed=42, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, gpu_id='0', variance=5, model_type='BSARec', max_seq_length=50, hidden_size=64, num_hidden_layers=2, hidden_act='gelu', num_attention_heads=1, attention_probs_dropout_prob=0.5, hidden_dropout_prob=0.5, initializer_range=0.02, c=5, alpha=0.7, cuda_condition=True, data_file='./data/Beauty.txt', item_size=12102, checkpoint_path='output/Jan-06-2025_14-11-15.pt', same_target_path='./data/Beauty_same_target.npy')
2025-01-06 14:11:17,005 - BSARecModel(
  (item_embeddings): Embedding(12102, 64, padding_idx=0)
  (position_embeddings): Embedding(50, 64)
  (LayerNorm): LayerNorm()
  (dropout): Dropout(p=0.5, inplace=False)
  (item_encoder): BSARecEncoder(
    (blocks): ModuleList(
      (0): BSARecBlock(
        (layer): BSARecLayer(
          (filter_layer): FrequencyLayer(
            (out_dropout): Dropout(p=0.5, inplace=False)
            (LayerNorm): LayerNorm()
          )
          (attention_layer): MultiHeadAttention(
            (query): Linear(in_features=64, out_features=64, bias=True)
            (key): Linear(in_features=64, out_features=64, bias=True)
            (value): Linear(in_features=64, out_features=64, bias=True)
            (softmax): Softmax(dim=-1)
            (attn_dropout): Dropout(p=0.5, inplace=False)
            (dense): Linear(in_features=64, out_features=64, bias=True)
            (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
            (out_dropout): Dropout(p=0.5, inplace=False)
          )
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
      (1): BSARecBlock(
        (layer): BSARecLayer(
          (filter_layer): FrequencyLayer(
            (out_dropout): Dropout(p=0.5, inplace=False)
            (LayerNorm): LayerNorm()
          )
          (attention_layer): MultiHeadAttention(
            (query): Linear(in_features=64, out_features=64, bias=True)
            (key): Linear(in_features=64, out_features=64, bias=True)
            (value): Linear(in_features=64, out_features=64, bias=True)
            (softmax): Softmax(dim=-1)
            (attn_dropout): Dropout(p=0.5, inplace=False)
            (dense): Linear(in_features=64, out_features=64, bias=True)
            (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
            (out_dropout): Dropout(p=0.5, inplace=False)
          )
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
)
2025-01-06 14:11:18,867 - Total Parameters: 878208
2025-01-06 14:11:18,928 - odict_keys(['item_embeddings.weight', 'position_embeddings.weight', 'LayerNorm.weight', 'LayerNorm.bias', 'item_encoder.blocks.0.layer.filter_layer.sqrt_beta', 'item_encoder.blocks.0.layer.filter_layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.filter_layer.LayerNorm.bias', 'item_encoder.blocks.0.layer.attention_layer.query.weight', 'item_encoder.blocks.0.layer.attention_layer.query.bias', 'item_encoder.blocks.0.layer.attention_layer.key.weight', 'item_encoder.blocks.0.layer.attention_layer.key.bias', 'item_encoder.blocks.0.layer.attention_layer.value.weight', 'item_encoder.blocks.0.layer.attention_layer.value.bias', 'item_encoder.blocks.0.layer.attention_layer.dense.weight', 'item_encoder.blocks.0.layer.attention_layer.dense.bias', 'item_encoder.blocks.0.layer.attention_layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.attention_layer.LayerNorm.bias', 'item_encoder.blocks.0.feed_forward.dense_1.weight', 'item_encoder.blocks.0.feed_forward.dense_1.bias', 'item_encoder.blocks.0.feed_forward.dense_2.weight', 'item_encoder.blocks.0.feed_forward.dense_2.bias', 'item_encoder.blocks.0.feed_forward.LayerNorm.weight', 'item_encoder.blocks.0.feed_forward.LayerNorm.bias', 'item_encoder.blocks.1.layer.filter_layer.sqrt_beta', 'item_encoder.blocks.1.layer.filter_layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.filter_layer.LayerNorm.bias', 'item_encoder.blocks.1.layer.attention_layer.query.weight', 'item_encoder.blocks.1.layer.attention_layer.query.bias', 'item_encoder.blocks.1.layer.attention_layer.key.weight', 'item_encoder.blocks.1.layer.attention_layer.key.bias', 'item_encoder.blocks.1.layer.attention_layer.value.weight', 'item_encoder.blocks.1.layer.attention_layer.value.bias', 'item_encoder.blocks.1.layer.attention_layer.dense.weight', 'item_encoder.blocks.1.layer.attention_layer.dense.bias', 'item_encoder.blocks.1.layer.attention_layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.attention_layer.LayerNorm.bias', 'item_encoder.blocks.1.feed_forward.dense_1.weight', 'item_encoder.blocks.1.feed_forward.dense_1.bias', 'item_encoder.blocks.1.feed_forward.dense_2.weight', 'item_encoder.blocks.1.feed_forward.dense_2.bias', 'item_encoder.blocks.1.feed_forward.LayerNorm.weight', 'item_encoder.blocks.1.feed_forward.LayerNorm.bias'])
2025-01-06 14:11:18,934 - odict_keys(['item_embeddings.weight', 'position_embeddings.weight', 'LayerNorm.weight', 'LayerNorm.bias', 'item_encoder.blocks.0.layer.filter_layer.sqrt_beta', 'item_encoder.blocks.0.layer.filter_layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.filter_layer.LayerNorm.bias', 'item_encoder.blocks.0.layer.attention_layer.query.weight', 'item_encoder.blocks.0.layer.attention_layer.query.bias', 'item_encoder.blocks.0.layer.attention_layer.key.weight', 'item_encoder.blocks.0.layer.attention_layer.key.bias', 'item_encoder.blocks.0.layer.attention_layer.value.weight', 'item_encoder.blocks.0.layer.attention_layer.value.bias', 'item_encoder.blocks.0.layer.attention_layer.dense.weight', 'item_encoder.blocks.0.layer.attention_layer.dense.bias', 'item_encoder.blocks.0.layer.attention_layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.attention_layer.LayerNorm.bias', 'item_encoder.blocks.0.feed_forward.dense_1.weight', 'item_encoder.blocks.0.feed_forward.dense_1.bias', 'item_encoder.blocks.0.feed_forward.dense_2.weight', 'item_encoder.blocks.0.feed_forward.dense_2.bias', 'item_encoder.blocks.0.feed_forward.LayerNorm.weight', 'item_encoder.blocks.0.feed_forward.LayerNorm.bias', 'item_encoder.blocks.1.layer.filter_layer.sqrt_beta', 'item_encoder.blocks.1.layer.filter_layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.filter_layer.LayerNorm.bias', 'item_encoder.blocks.1.layer.attention_layer.query.weight', 'item_encoder.blocks.1.layer.attention_layer.query.bias', 'item_encoder.blocks.1.layer.attention_layer.key.weight', 'item_encoder.blocks.1.layer.attention_layer.key.bias', 'item_encoder.blocks.1.layer.attention_layer.value.weight', 'item_encoder.blocks.1.layer.attention_layer.value.bias', 'item_encoder.blocks.1.layer.attention_layer.dense.weight', 'item_encoder.blocks.1.layer.attention_layer.dense.bias', 'item_encoder.blocks.1.layer.attention_layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.attention_layer.LayerNorm.bias', 'item_encoder.blocks.1.feed_forward.dense_1.weight', 'item_encoder.blocks.1.feed_forward.dense_1.bias', 'item_encoder.blocks.1.feed_forward.dense_2.weight', 'item_encoder.blocks.1.feed_forward.dense_2.bias', 'item_encoder.blocks.1.feed_forward.LayerNorm.weight', 'item_encoder.blocks.1.feed_forward.LayerNorm.bias'])
2025-01-06 14:11:18,935 - Load model from output/BSARec_Beauty_best.pt for test!
2025-01-06 14:11:23,606 - {'Epoch': 0, 'HR@5': '0.0735', 'NDCG@5': '0.0523', 'HR@10': '0.1008', 'NDCG@10': '0.0611', 'HR@20': '0.1373', 'NDCG@20': '0.0703'}
2025-01-06 14:11:23,607 - Jan-06-2025_14-11-15
2025-01-06 14:11:23,607 - {'Epoch': 0, 'HR@5': '0.0735', 'NDCG@5': '0.0523', 'HR@10': '0.1008', 'NDCG@10': '0.0611', 'HR@20': '0.1373', 'NDCG@20': '0.0703'}
